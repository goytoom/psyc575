colnames(table) <- c("Model", "variance_country", "variance_income", "variance_individual", "intercept", "slope_income", "slope_GNP", "interaction")
table[1,] <- c(3, 0.067, 0.0015, 0.465, 2.98, 0.047, "-", "-")
table[2,] <- c(4, 0.0378, 0.0011, 0.465, 2.98, 0.047, 0.18, -0.021)
kable(table, "latex", booktabs = T) %>%
kable_styling(latex_options = c("striped", "scale_down"))
# Create a table containing the previous models coefficient
table <- as.data.frame(matrix(ncol=8))
colnames(table) <- c("Model", "variance_country", "variance_income", "variance_individual", "intercept", "slope_income", "slope_GNP", "interaction")
table[1,] <- c(3, 0.067, 0.0015, 0.465, 2.98, 0.047, "-", "-")
table[2,] <- c(4, 0.0378, 0.0011, 0.465, 2.98, 0.047, 0.18, -0.021)
kable(table) %>%
kable_styling(latex_options = c("striped", "scale_down"))
kable(table, "latex") %>%
kable_styling(latex_options = c("striped", "scale_down"))
# Create a table containing the previous models coefficient
table <- as.data.frame(matrix(ncol=8))
colnames(table) <- c("Model", "variance_country", "variance_income", "variance_individual", "intercept", "slope_income", "slope_GNP", "interaction")
table[1,] <- c(3, 0.067, 0.0015, 0.465, 2.98, 0.047, "-", "-")
table[2,] <- c(4, 0.0378, 0.0011, 0.465, 2.98, 0.047, 0.18, -0.021)
kable(table, "latex") %>%
kable_styling(latex_options = c("striped", "scale_down"))
kable(table, format="latex") %>%
kable_styling(latex_options = c("striped", "scale_down"))
# Create a table containing the previous models coefficient
table <- as.data.frame(matrix(ncol=8))
colnames(table) <- c("Model", "variance_country", "variance_income", "variance_individual", "intercept", "slope_income", "slope_GNP", "interaction")
table[1,] <- c(3, 0.067, 0.0015, 0.465, 2.98, 0.047, "-", "-")
table[2,] <- c(4, 0.0378, 0.0011, 0.465, 2.98, 0.047, 0.18, -0.021)
kable(table, format="latex") %>%
kable_styling(latex_options = c("striped", "scale_down"))
library(knitr)
# Create a table containing the previous models coefficient
table <- as.data.frame(matrix(ncol=8))
colnames(table) <- c("Model", "variance_country", "variance_income", "variance_individual", "intercept", "slope_income", "slope_GNP", "interaction")
table[1,] <- c(3, 0.067, 0.0015, 0.465, 2.98, 0.047, "-", "-")
table[2,] <- c(4, 0.0378, 0.0011, 0.465, 2.98, 0.047, 0.18, -0.021)
kable(table, format="latex") %>%
kable_styling(latex_options = c("striped", "scale_down"))
kable(table, format="latex", booktabs = T) %>%
kable_styling(latex_options = c("striped", "scale_down"))
kable(table, booktabs = T) %>%
kable_styling(latex_options = c("striped", "scale_down"))
# Create a table containing the previous models coefficient
table <- as.data.frame(matrix(ncol=8))
colnames(table) <- c("Model", "variance_country", "variance_income", "variance_individual", "intercept", "slope_income", "slope_GNP", "interaction")
table[1,] <- c(3, 0.067, 0.0015, 0.465, 2.98, 0.047, "-", "-")
table[2,] <- c(4, 0.0378, 0.0011, 0.465, 2.98, 0.047, 0.18, -0.021)
knitr::kable(table, format="latex", booktabs = T) %>%
kable_styling(latex_options = c("striped", "scale_down"))
# Create a table containing the previous models coefficient
table <- as.data.frame(matrix(ncol=8))
colnames(table) <- c("Model", "variance_country", "variance_income", "variance_individual", "intercept", "slope_income", "slope_GNP", "interaction")
table[1,] <- c(3, 0.067, 0.0015, 0.465, 2.98, 0.047, "-", "-")
table[2,] <- c(4, 0.0378, 0.0011, 0.465, 2.98, 0.047, 0.18, -0.021)
knitr::kable(table, format="latex", booktabs = T) %>%
kable_styling(latex_options = c("striped", "scale_down"))
knitr::kable(table, format="html", booktabs = T) %>%
kable_styling(latex_options = c("striped", "scale_down"))
knitr::kable(table, booktabs = T) %>%
kable_styling(latex_options = c("striped", "scale_down"))
knitr::kable(table, format = "latex", booktabs = T) %>%
kable_styling(latex_options = c("striped", "scale_down"))
# Create a table containing the previous models coefficient
table <- as.data.frame(matrix(ncol=8))
colnames(table) <- c("Model", "variance_country", "variance_income", "variance_individual", "intercept", "slope_income", "slope_GNP", "interaction")
table[1,] <- c(3, 0.067, 0.0015, 0.465, 2.98, 0.047, "-", "-")
table[2,] <- c(4, 0.0378, 0.0011, 0.465, 2.98, 0.047, 0.18, -0.021)
knitr::kable(table, format = "latex", booktabs = T) %>%
kable_styling(latex_options = c("striped", "scale_down"))
knitr::kable(table, format = "hmtl", booktabs = T) %>%
kable_styling(c("striped", "scale_down"))
# Create a table containing the previous models coefficient
table <- as.data.frame(matrix(ncol=8))
colnames(table) <- c("Model", "variance_country", "variance_income", "variance_individual", "intercept", "slope_income", "slope_GNP", "interaction")
table[1,] <- c(3, 0.067, 0.0015, 0.465, 2.98, 0.047, "-", "-")
table[2,] <- c(4, 0.0378, 0.0011, 0.465, 2.98, 0.047, 0.18, -0.021)
knitr::kable(table, format = "hmtl", booktabs = T) %>%
kable_styling(c("striped", "scale_down"))
# Create a table containing the previous models coefficient
table <- as.data.frame(matrix(ncol=8))
colnames(table) <- c("Model", "variance_country", "variance_income", "variance_individual", "intercept", "slope_income", "slope_GNP", "interaction")
table[1,] <- c(3, 0.067, 0.0015, 0.465, 2.98, 0.047, "-", "-")
table[2,] <- c(4, 0.0378, 0.0011, 0.465, 2.98, 0.047, 0.18, -0.021)
knitr::kable(table, booktabs = T) %>%
kable_styling(c("striped", "scale_down"))
knitr::kable(table, booktabs = T) %>%
kable_styling(width = "scale_down")
# Create a table containing the previous models coefficient
table <- as.data.frame(matrix(ncol=8))
colnames(table) <- c("Model", "variance_country", "variance_income", "variance_individual", "intercept", "slope_income", "slope_GNP", "interaction")
table[1,] <- c(3, 0.067, 0.0015, 0.465, 2.98, 0.047, "-", "-")
table[2,] <- c(4, 0.0378, 0.0011, 0.465, 2.98, 0.047, 0.18, -0.021)
knitr::kable(table, booktabs = T) %>%
kable_styling(width = "8cm")
knitr::kable(table, booktabs = T) %>%
kable_styling(1, width = "8cm")
# Create a table containing the previous models coefficient
table <- as.data.frame(matrix(ncol=8))
colnames(table) <- c("Model", "variance_country", "variance_income", "variance_individual", "intercept", "slope_income", "slope_GNP", "interaction")
table[1,] <- c(3, 0.067, 0.0015, 0.465, 2.98, 0.047, "-", "-")
table[2,] <- c(4, 0.0378, 0.0011, 0.465, 2.98, 0.047, 0.18, -0.021)
knitr::kable(table, booktabs = T) %>%
kable_styling(latex_options = "striped"))
knitr::kable(table, booktabs = T) %>%
kable_styling(latex_options = "striped")
knitr::kable(table, booktabs = T) %>%
kable_styling(latex_options = "scale_down")
knitr::opts_chunk$set(echo = TRUE)
#Install packages if not already installed:
list.of.packages <- c("lmerTest", "lme4", 'broom.mixed', 'modelsummary', "MuMIn", 'kableExtra', "remotes", "pbkrtest", "haven")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)){
install.packages(new.packages)
lapply(new.packages, require, character.only = TRUE)
}
#bayesian:
#rstanarm, brms, MCMCglmm
#add automatic activation of package
# Add additional packages you need
library(tidyverse)  # for data manipulation and plotting
library(lmerTest)  # for importing SPSS/SAS/Stata data
library(lme4)  # for multilevel analysis
library(MuMIn)  # for computing r-squared
library(broom.mixed)  # for summarizing results
library(modelsummary)  # for making tables
library(remotes)
library(pbkrtest)
library(haven)
theme_set(theme_bw())  # Theme; just my personal preference
remotes::install_github("marklhc/bootmlm")
library(bootmlm)
library(boot)
set.seed(0) # seed for random initiation
happy_dat <- read_sav("happy_combined.sav")
(country_subset <- sample(unique(happy_dat$country), size = 10)) #choose 10 random countries
happy_sub <- happy_dat %>% #save random subset
filter(country %in% country_subset)
#Fit model using REML (standard)
m1 <- lmer(happy ~ income_cm + income + (income|country), data = happy_sub)
#create mean income variable for each country and centre individual income by country mean
happy_sub <- happy_sub %>% group_by(country) %>%
mutate(income_cm = mean(income), income_cmc = income - mean(income)) %>% ungroup()
#Fit model using REML (standard)
m1 <- lmer(happy ~ income_cm + income + (income|country), data = happy_sub)
summary(m1)
#Fit model using ML
m2 <- lmer(happy ~ income_cm + income + (income|country), data = happy_sub, REML = F)
summary(m2)
#Fit model using REML with Kenward-Roger correction
m3 <- as_lmerModLmerTest(m1)
summary(m3, ddf="Kenward-Roger")
#fit without random slope:
m0 <- lmer(happy ~ income_cm + income + (1|country), data = happy_sub) #without random slopes
dev_diff <- REMLcrit(m0) - REMLcrit(m3)        #Compute difference in deviance to model with random slopes
pchisq(dev_diff, df = 2, lower.tail = FALSE)/2   #Chisq test; divide p value by two to adjust for one sided testing (> 0)
#Test the fixed effects using kenward roger correction
# Try anova()
anova(m3, ddf = "Kenward-Roger")
#use residual bootstrapping to calculate confidence for marginal r2
boot_r2 <- bootstrap_mer(m3, MuMIn::r.squaredGLMM, nsim = 999,
type = "residual") #bootstrapping
#confidence interval
boot.ci(boot_r2, index = 1, type = "perc")  # index = 1 for marginal R2
#get estimate for marginal r2 for reml model with kenward roger correction
r.squaredGLMM(m3)
bootstrap_mer(m3, fixef, nsim = 999,
type = "residual") #bootstrapping
#use residual bootstrapping to calculate confidence for marginal r2
boot_r2 <- bootstrap_mer(m3, MuMIn::r.squaredGLMM, nsim = 999,
type = "residual") #bootstrapping
#confidence interval
boot.ci(boot_r2, index = 1, type = "perc")  # index = 1 for marginal R2
#get estimate for marginal r2 for reml model with kenward roger correction
r.squaredGLMM(m3)
?isSingular
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lme4)
library(lmerTest)
# Data from Shrout & Fleiss (1979)
sf <- matrix(
c(9, 2, 5, 8,
6, 1, 3, 2,
8, 4, 6, 8,
7, 1, 2, 6,
10, 5, 6, 9,
6, 2, 4, 7),
ncol = 4,
byrow = TRUE
)
colnames(sf) <- paste("judge", 1:4, sep = "")
rownames(sf) <- paste("target", 1:6, sep = "")
sf
# Convert to long format
sf_long <- sf %>%
as.data.frame() %>%
rownames_to_column("target") %>%
pivot_longer(cols = judge1:judge4,
names_to = "judge",
values_to = "rating")
# Simulate an additional treatment variable
sf_long$trained <- rep(c(0, 1), each = 12)
sf_long
m1 <- lmer(rating ~ (1|target) + (1|judge), data=sf_long)
re_dat       = as.data.frame(VarCorr(m1))  #get variance of random effects
judge_icc    = re_dat$vcov[2]/sum(re_dat$vcov)         #subject ICC
judge_icc
View(data)
View(data)
data2 <- data %>% rowwise()
library(tidyverse)
data2 <- data %>% rowwise()
data2 <- data %>% rowwise() %>% mutate(nmis =  sum(is.na(c_across(country:gm_GNP))),
# Complete only when nmis_read = 0
complete = if_else(nmis_read == 0, "complete", "incomplete")) %>%
ungroup()
knitr::opts_chunk$set(echo = TRUE, comment = ">#")
# To install a package, run the following ONCE (and only once on your computer)
# install.packages("psych")
library(here)  # makes reading data more consistent
library(tidyverse)  # for data manipulation and plotting
library(haven)  # for importing SPSS/SAS/Stata data
library(lme4)  # for multilevel analysis
library(glmmTMB)  # for longitudinal analysis
# To install a package, run the following ONCE (and only once on your computer)
# install.packages("psych")
library(here)  # makes reading data more consistent
library(tidyverse)  # for data manipulation and plotting
library(haven)  # for importing SPSS/SAS/Stata data
library(lme4)  # for multilevel analysis
library(glmmTMB)  # for longitudinal analysis
library(modelsummary)  # for making tables
library(interactions)  # for interaction plots
theme_set(theme_bw())  # Theme; just my personal preference
# Read in the data from gitHub (need Internet access)
curran_wide <- read_sav("https://github.com/MultiLevelAnalysis/Datasets-third-edition-Multilevel-book/raw/master/chapter%205/Curran/CurranData.sav")
# Make id a factor
curran_wide  # print the data
# Using the new `tidyr::pivot_longer()` function
curran_long <- curran_wide %>%
pivot_longer(
c(anti1:anti4, read1:read4),  # variables that are repeated measures
# Convert 8 columns to 3: 2 columns each for anti/read (.value), and
# one column for time
names_to = c(".value", "time"),
# Extract the names "anti"/"read" from the names of the variables for the
# value columns, and then the number to the "time" column
names_pattern = "(anti|read)([1-4])",
# Convert the "time" column to integers
names_transform = list(time = as.integer)
)
curran_long %>%
select(id, anti, read, time, everything())
curran_long %>%
select(time, kidage, homecog, anti, read) %>%
psych::pairs.panels(jiggle = TRUE, factor = 0.5, ellipses = FALSE,
cex.cor = 1, cex = 0.5)
# Plotting
p1 <- ggplot(curran_long, aes(x = time, y = read)) +
geom_point() +
geom_line(aes(group = id)) +  # add lines to connect the data for each person
# add a mean trajectory
stat_summary(fun = "mean", col = "red", size = 1, geom = "line")
p1
# Randomly sample 40 individuals
set.seed(1349)
sampled_id <- sample(unique(curran_long$id), 40)
curran_long %>%
filter(id %in% sampled_id) %>%
ggplot(aes(x = time, y = read)) +
geom_point() +
geom_line() +  # add lines to connect the data for each person
facet_wrap(~ id, ncol = 10)
# Easier with the wide data set
# Covariance matrix:
curran_wide %>%
select(starts_with("read")) %>%
cov(use = "complete") %>%   # listwise deletion
round(2L)  # two decimal places
# Correlation matrix
curran_wide %>%
select(starts_with("read")) %>%
cor(use = "complete") %>%   # listwise deletion
round(2L)  # two decimal places
# Create grouping
curran_wide <- curran_wide %>%
# Compute summaries by rows
rowwise() %>%
# First compute the number of missing occasions
mutate(nmis_read = sum(is.na(c_across(read1:read4))),
# Complete only when nmis_read = 0
complete = if_else(nmis_read == 0, "complete", "incomplete")) %>%
ungroup()
# Compare the differences
datasummary((anti1 + read1 + kidgen + momage + kidage + homecog + homeemo) ~
complete * (Mean + SD), data = curran_wide)
View(curran_wide)
# Create grouping
curran_wide <- curran_wide %>%
# Compute summaries by rows
# rowwise() %>%
# First compute the number of missing occasions
mutate(nmis_read = sum(is.na(c_across(read1:read4))),
# Complete only when nmis_read = 0
complete = if_else(nmis_read == 0, "complete", "incomplete")) #%>%
# ungroup()
# Compare the differences
datasummary((anti1 + read1 + kidgen + momage + kidage + homecog + homeemo) ~
complete * (Mean + SD), data = curran_wide)
View(curran_wide)
# Create grouping
curran_wide <- curran_wide %>%
# Compute summaries by rows
rowwise() %>%
# First compute the number of missing occasions
mutate(nmis_read = sum(is.na(c_across(read1:read4))),
# Complete only when nmis_read = 0
complete = if_else(nmis_read == 0, "complete", "incomplete")) %>%
ungroup()
# Compare the differences
datasummary((anti1 + read1 + kidgen + momage + kidage + homecog + homeemo) ~
complete * (Mean + SD), data = curran_wide)
m00_lme4 <- lmer(read ~ (1 | id), data = curran_long)
summary(m00_lme4)
# Default in glmmTMB is ML; need to specify REML is desired
m00 <- glmmTMB(read ~ (1 | id), data = curran_long, REML = TRUE)
summary(m00)
(vc_m00 <- VarCorr(m00))  # shows the random effect SDs
vc_m00[[1]]$id[1, 1]  # intercept variance (tau_0^2)
attr(vc_m00[[1]], "sc")^2  # lv-1 error variance (sigma^2)
# ICC: tau_0^2 / (tau_0^2 + sigma^2)
vc_m00[[1]]$id[1, 1] /
(vc_m00[[1]]$id[1, 1] + attr(vc_m00[[1]], "sc")^2)
ttr(vc_m00[[1]], "sc")
attr(vc_m00[[1]], "sc")
(vc_m00 <- VarCorr(m00))
vc_m00[[1]]$id[1, 1]
attr(vc_m00[[1]], "sc")^2
install.packages('usethis')
library(usethis)
use_git_config(user.name=goytoom)
use_git_config(user.name="Suhaib Abdurahman")
use_git_config(user.email="suhaib.abdurahman@gmail.com")
git config --global --list
git --version
library(gitcreds)
git --version
setwd("G:/My Drive/PhD/Current Semester/575/psyc575")
df <- read.table("HATCH_timewbaby_wdw.csv")
df <- read.table("HATCH_timewbaby_wdw.csv")
df <- read.table("HATCH_timewbaby_wdw.csv", sep = "\t")
View(df)
df <- read.table("HATCH_timewbaby_wdw.csv", sep = ",")
View(df)
df <- read.table("HATCH_timewbaby_wdw.csv", sep = ",", header = T)
View(df)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(haven)
library(ggplot2)
library(here)
library(jtools)
library(lme4)
library(lmerTest)
library(glmmTMB)
library(modelsummary)
theme_set(jtools::theme_apa())
# Read in the data
df.hatch <- read_sav(here("HATCH 09.29.21.sav"))
# Subset Variables
df.mlm <- df.hatch %>%
select(c(CoupID,                                # Couple ID
# Couple Level                         ## COUPLE ##
DelMod, ModeofDeliverySpecific,        # Delivery Method
GesAgeWk,                              # Gestational age
Bb.sex,                                # Baby sex
# Person Level                         ## PERSON ##
contains("pnAge"),                     # Parent age
contains("Ethn"),                      # Parent ethnicity
contains("Educ"),                      # Parent level of education
contains("peritot"),                   # BEQ (birth stress)
# Time Level                           ## TIME ##
bage3pp.1, bage6pp, bage12pp.1,        # Baby age
contains("PSI_t"),                     # Parenting Stress
contains("PSIt"),
contains("PSI.t")
))
# Rename Variables
colnames(df.mlm) <- c("CoupID",
# Couple Level
"DelMeth", "DelMeth.Specific",
"GestationAge",
"BabySex",
# Person Level
"age.mom", "age.dad",
"ethnicity.mom", "ethnicity.dad",
"education.mom", "education.dad",
"beq.mom", "beq.dad",
# Time Level
"BabyAge.3", "BabyAge.6", "BabyAge.12",
"PSI.3.mom", "PSI.12.mom", "PSI.12.dad",
"PSI.3.dad", "PSI.6.dad",
"PSI.6.mom"
)
# Reorder PSI Variables
df.mlm <- df.mlm %>%
relocate(c("PSI.3.mom", "PSI.3.dad",
"PSI.6.mom", "PSI.6.dad",
"PSI.12.mom", "PSI.12.dad"),
.after = BabyAge.12)
# Subset Variables
df.mlm <- df.hatch %>%
select(c(CoupID,                                # Couple ID
# Couple Level                         ## COUPLE ##
DelMod, ModeofDeliverySpecific,        # Delivery Method
GesAgeWk,                              # Gestational age
Bb.sex,                                # Baby sex
# Person Level                         ## PERSON ##
contains("pnAge"),                     # Parent age
contains("Ethn"),                      # Parent ethnicity
contains("Educ"),                      # Parent level of education
contains("peritot"),                   # BEQ (birth stress)
# Time Level                           ## TIME ##
bage3pp.1, bage6pp, bage12pp.1,        # Baby age
contains("PSI_t"),                     # Parenting Stress
contains("PSIt"),
contains("PSI.t")
))
# Rename Variables
colnames(df.mlm) <- c("CoupID",
# Couple Level
"DelMeth", "DelMeth.Specific",
"GestationAge",
"BabySex",
# Person Level
"age.mom", "age.dad",
"ethnicity.mom", "ethnicity.dad",
"education.mom", "education.dad",
"beq.mom", "beq.dad",
# Time Level
"BabyAge.3", "BabyAge.6", "BabyAge.12",
"PSI.3.mom", "PSI.12.mom", "PSI.12.dad",
"PSI.3.dad", "PSI.6.dad",
"PSI.6.mom"
)
# Reorder PSI Variables
df.mlm <- df.mlm %>%
relocate(c("PSI.3.mom", "PSI.3.dad",
"PSI.6.mom", "PSI.6.dad",
"PSI.12.mom", "PSI.12.dad"),
.after = BabyAge.12)
# Person-Level and Time-Level Variables
df.long1 <- df.mlm %>%
# Parent-level variables
pivot_longer(
cols = age.mom:beq.dad,
names_to = c(".value", "parent"),
names_pattern = "(age|ethnicity|education|beq).(mom|dad)",
names_transform = list(parent = as.factor)
) %>%
# Assign participant IDs
mutate(PersonID = seq(1:200)) %>%
# Time-level variables
pivot_longer(
cols = BabyAge.3:BabyAge.12,
names_to = c(".value", "time"),
names_pattern = "(BabyAge).(3|6|12)",
names_transform = list(time = as.integer)
) %>%
# Remove PSI variables
select(-starts_with("PSI"))
# PSI Variable
df.long2 <- df.mlm %>%
pivot_longer(
cols = PSI.3.mom:PSI.12.dad,
names_to = c(".value", "time", "parent"),
names_pattern = "(PSI).(3|6|12).(mom|dad)",
names_transform = list(time = as.integer, parent = as.factor)
) %>%
# Remove variables in `df.long1` that aren't identifying variables
select(c(CoupID, time, parent, PSI))
# Combine Data Frames
df.long <- left_join(df.long1, df.long2, by = c("CoupID", "parent", "time")) %>%
# Move identifying variable
relocate(c(PersonID, parent, time), .after = CoupID) %>%
# Remove funky formatting
mutate(beq = na_if(beq, -97.450))
#scaling and decomposing of variables
df_scaled <- df.long %>% mutate(log_psi = scale(log(PSI))) %>%
group_by(CoupID) %>% mutate(beq_cm = mean(beq)) %>% ungroup() %>% mutate(beq_cmc = beq - beq_cm)
m0 <- lmer(PSI ~ 1 + (time|CoupID), data=df_scaled)
ranova(m0) #not significant!
#random slope insignificant for Couples and does not converge for Persons
m1 <- glmmTMB(PSI ~ time + beq_cmc  + DelMeth*beq_cm + (1|PersonID) + (1|CoupID), data = df_scaled)
summary(m1) #robust se estimation (faster than brms)
# m2 <- glmmTMB(PSI ~ time + beq_cmc  + DelMeth*beq_cm + age + parent + (1|PersonID) + (time|CoupID), data = df_scaled)
# summary(m2) #robust se estimation (faster than brms)
modelsummary(m1, group = group + term ~ model)
effect_plot(m1, pred = beq_cmc,interval = TRUE, plot.points = TRUE)
# ggplot(data = df_scaled, aes(x = beq, y=PSI, group=CoupID))+
#   geom_point()+
#   geom_smooth(method = "lm", se = F, aes(colour = CoupID))+
#   xlab("Birth experience")+ylab("Parental Stress")+
#   theme(legend.position = "none")
update.packages(ask = FALSE, checkBuilt = TRUE)
tinytex::tlmgr_update()
knitr::opts_chunk$set(echo = TRUE)
options(tinytex.verbose = TRUE)
library(kabelExtra)
install.packages("kabelExtra")
library(kabelExtra)
library(kableExtra)
